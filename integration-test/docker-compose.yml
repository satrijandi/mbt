services:
  postgres:
    image: postgres:16
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin_password
    volumes:
      - ./infra/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin"]
      interval: 5s
      timeout: 5s
      retries: 5

  seaweedfs-master:
    image: chrislusf/seaweedfs
    command: "master -ip=seaweedfs-master -ip.bind=0.0.0.0"
    ports:
      - "9333:9333"

  seaweedfs-volume:
    image: chrislusf/seaweedfs
    command: "volume -mserver=seaweedfs-master:9333 -ip.bind=0.0.0.0 -port=8080"
    depends_on:
      - seaweedfs-master

  seaweedfs-filer:
    image: chrislusf/seaweedfs
    command: "filer -master=seaweedfs-master:9333 -ip.bind=0.0.0.0 -s3"
    ports:
      - "8333:8333"
      - "8888:8888"
    depends_on:
      - seaweedfs-master
      - seaweedfs-volume

  mlflow:
    build: ./infra/mlflow
    command: >
      mlflow server
      --backend-store-uri postgresql://mlflow_user:mlflow_password@postgres:5432/mlflow_db
      --default-artifact-root s3://mbt-mlflow-artifacts/
      --host 0.0.0.0
      --port 5000
    ports:
      - "5000:5000"
    environment:
      AWS_ACCESS_KEY_ID: ""
      AWS_SECRET_ACCESS_KEY: ""
      MLFLOW_S3_ENDPOINT_URL: http://seaweedfs-filer:8333
    depends_on:
      postgres:
        condition: service_healthy
      seaweedfs-filer:
        condition: service_started

  airflow-init:
    build:
      context: ..
      dockerfile: integration-test/infra/airflow/Dockerfile
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db init &&
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://airflow_user:airflow_password@postgres:5432/airflow_db
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    depends_on:
      postgres:
        condition: service_healthy

  airflow-webserver:
    build:
      context: ..
      dockerfile: integration-test/infra/airflow/Dockerfile
    command: webserver
    ports:
      - "8080:8080"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://airflow_user:airflow_password@postgres:5432/airflow_db
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      MLFLOW_S3_ENDPOINT_URL: http://seaweedfs-filer:8333
      AWS_ACCESS_KEY_ID: "any"
      AWS_SECRET_ACCESS_KEY: "any"
    volumes:
      - ./generated_dags:/opt/airflow/dags
      - ./project:/opt/airflow/project
    depends_on:
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    build:
      context: ..
      dockerfile: integration-test/infra/airflow/Dockerfile
    command: scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql://airflow_user:airflow_password@postgres:5432/airflow_db
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      MLFLOW_S3_ENDPOINT_URL: http://seaweedfs-filer:8333
      AWS_ACCESS_KEY_ID: "any"
      AWS_SECRET_ACCESS_KEY: "any"
    volumes:
      - ./generated_dags:/opt/airflow/dags
      - ./project:/opt/airflow/project
    depends_on:
      airflow-init:
        condition: service_completed_successfully

volumes:
  pg_data:
